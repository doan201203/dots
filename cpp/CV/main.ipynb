{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['938_IMG_20180911_214011.jpg', '1020_IMG_20180928_225945.jpg', '634_IMG_20180116_204337.jpg', '960_IMG_20180928_203050.jpg', '928_IMG_20180911_213444.jpg', 'bayan_box6_c52db94d-07bf-4c93-8b95-f5e11fae27dd.jpg', '914_IMG_20180911_212553.jpg', '937_IMG_20180911_213945.jpg', '939_IMG_20180911_214553.jpg', '933_IMG_20180911_213748.jpg']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images_path = os.path.join(os.getcwd(), './ImageSets')\n",
    "annotations_path = os.path.join(os.getcwd(), './SegmentationClass')\n",
    "\n",
    "images_name = os.listdir(images_path)\n",
    "annotations_name = os.listdir(annotations_path)\n",
    "\n",
    "images_name_train, images_name_test, annotations_name_train, annotations_name_test = train_test_split(images_name, annotations_name, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiaChua [22.32865176 26.5294368  28.75540845] [ 94.12402998 105.11477611 111.13636997]\n",
      "VungVoKhuan [24.44361592 31.05768595 34.75743175] [ 94.2651039  105.48941881 111.11809824]\n",
      "GiayKhangSinh [23.12287935 30.29840479 33.33883135] [ 99.48786759 110.57353913 116.28823017]\n"
     ]
    }
   ],
   "source": [
    "from ThresholdModel import ThresholdModel\n",
    "\n",
    "model = ThresholdModel(images_path, annotations_path)\n",
    "model.add_label('DiaChua', [255, 221, 51])\n",
    "model.add_label('VungVoKhuan', [102, 255, 102])\n",
    "model.add_label('GiayKhangSinh', [240, 120, 240])\n",
    "\n",
    "model.fit(images_name_train, annotations_name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938_IMG_20180911_214011.jpg 0.2456 0.5867 0.0349\n",
      "1020_IMG_20180928_225945.jpg 0.2439 0.0405 0.0087\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3968,2976,3) (4128,3096,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m mask_GiayKhangSinh \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(image_test, \u001b[39m'\u001b[39m\u001b[39mGiayKhangSinh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m accuracy[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(image_name)\n\u001b[0;32m---> 22\u001b[0m accuracy[\u001b[39m'\u001b[39m\u001b[39mDiaChua\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(iou_measure(mask_DiaChua, model\u001b[39m.\u001b[39;49mget_mask(annotation_test, \u001b[39m'\u001b[39;49m\u001b[39mDiaChua\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m     23\u001b[0m accuracy[\u001b[39m'\u001b[39m\u001b[39mVungVoKhuan\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(iou_measure(mask_VungVoKhuan, model\u001b[39m.\u001b[39mget_mask(annotation_test, \u001b[39m'\u001b[39m\u001b[39mVungVoKhuan\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m     24\u001b[0m accuracy[\u001b[39m'\u001b[39m\u001b[39mGiayKhangSinh\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(iou_measure(mask_GiayKhangSinh, model\u001b[39m.\u001b[39mget_mask(annotation_test, \u001b[39m'\u001b[39m\u001b[39mGiayKhangSinh\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "File \u001b[0;32m~/dev/cpp/CV/ThresholdModel.py:76\u001b[0m, in \u001b[0;36miou_measure\u001b[0;34m(predict, mask)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miou_measure\u001b[39m(predict: np\u001b[39m.\u001b[39mndarray, mask: np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m---> 76\u001b[0m     intersect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mall((predict \u001b[39m&\u001b[39;49m mask) \u001b[39m!=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     77\u001b[0m     union \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mall((predict \u001b[39m|\u001b[39m mask) \u001b[39m!=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m intersect \u001b[39m/\u001b[39m union\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3968,2976,3) (4128,3096,3) "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ThresholdModel import iou_measure\n",
    "\n",
    "accuracy = {\n",
    "    'name': [],\n",
    "    'DiaChua': [],\n",
    "    'VungVoKhuan': [],\n",
    "    'GiayKhangSinh': []\n",
    "}\n",
    "\n",
    "for image_name, annotation_name in zip(images_name_test, annotations_name_test):\n",
    "    image_test = cv2.imread(os.path.join(images_path, image_name))\n",
    "    annotation_test = cv2.imread(os.path.join(annotations_path, annotation_name))\n",
    "    \n",
    "    mask_DiaChua = model.predict(image_test, 'DiaChua')\n",
    "    mask_VungVoKhuan = model.predict(image_test, 'VungVoKhuan')\n",
    "    mask_GiayKhangSinh = model.predict(image_test, 'GiayKhangSinh')\n",
    "    \n",
    "    accuracy['name'].append(image_name)\n",
    "    accuracy['DiaChua'].append(iou_measure(mask_DiaChua, model.get_mask(annotation_test, 'DiaChua')))\n",
    "    accuracy['VungVoKhuan'].append(iou_measure(mask_VungVoKhuan, model.get_mask(annotation_test, 'VungVoKhuan')))\n",
    "    accuracy['GiayKhangSinh'].append(iou_measure(mask_GiayKhangSinh, model.get_mask(annotation_test, 'GiayKhangSinh')))\n",
    "\n",
    "    print('%s %.4f %.4f %.4f' % (accuracy['name'][-1], accuracy['DiaChua'][-1], accuracy['VungVoKhuan'][-1], accuracy['GiayKhangSinh'][-1]))\n",
    "\n",
    "output = pd.DataFrame(accuracy)\n",
    "output.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>DiaChua</th>\n",
       "      <th>VungVoKhuan</th>\n",
       "      <th>GiayKhangSinh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>879_IMG_20180911_195128.jpg</td>\n",
       "      <td>0.342546</td>\n",
       "      <td>0.205640</td>\n",
       "      <td>0.004145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>873_IMG_20180911_194441.jpg</td>\n",
       "      <td>0.443808</td>\n",
       "      <td>0.647355</td>\n",
       "      <td>0.111040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>870_IMG_20180911_194225.jpg</td>\n",
       "      <td>0.591059</td>\n",
       "      <td>0.517454</td>\n",
       "      <td>0.102696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>880_IMG_20180911_195205.jpg</td>\n",
       "      <td>0.341821</td>\n",
       "      <td>0.413190</td>\n",
       "      <td>0.034984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>868_IMG_20180911_194036.jpg</td>\n",
       "      <td>0.248475</td>\n",
       "      <td>0.788308</td>\n",
       "      <td>0.058259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nadia_box5_75c28c60-77e5-4236-9a1a-828f506caf1...</td>\n",
       "      <td>0.712071</td>\n",
       "      <td>0.205207</td>\n",
       "      <td>0.046006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>877_IMG_20180911_194847.jpg</td>\n",
       "      <td>0.349340</td>\n",
       "      <td>0.447334</td>\n",
       "      <td>0.020887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hadeel_box6_3620256a-d309-44ad-9dd7-f649ecf9a8...</td>\n",
       "      <td>0.133761</td>\n",
       "      <td>0.347276</td>\n",
       "      <td>0.009725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>882_IMG_20180911_195412.jpg</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>0.654529</td>\n",
       "      <td>0.085512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   DiaChua  VungVoKhuan  \\\n",
       "0                        879_IMG_20180911_195128.jpg  0.342546     0.205640   \n",
       "1                        873_IMG_20180911_194441.jpg  0.443808     0.647355   \n",
       "2                        870_IMG_20180911_194225.jpg  0.591059     0.517454   \n",
       "3                        880_IMG_20180911_195205.jpg  0.341821     0.413190   \n",
       "4                        868_IMG_20180911_194036.jpg  0.248475     0.788308   \n",
       "5  nadia_box5_75c28c60-77e5-4236-9a1a-828f506caf1...  0.712071     0.205207   \n",
       "6                        877_IMG_20180911_194847.jpg  0.349340     0.447334   \n",
       "7  hadeel_box6_3620256a-d309-44ad-9dd7-f649ecf9a8...  0.133761     0.347276   \n",
       "8                        882_IMG_20180911_195412.jpg  0.499081     0.654529   \n",
       "\n",
       "   GiayKhangSinh  \n",
       "0       0.004145  \n",
       "1       0.111040  \n",
       "2       0.102696  \n",
       "3       0.034984  \n",
       "4       0.058259  \n",
       "5       0.046006  \n",
       "6       0.020887  \n",
       "7       0.009725  \n",
       "8       0.085512  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
